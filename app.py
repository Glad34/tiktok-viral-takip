import streamlit as st
import pandas as pd
from apify_client import ApifyClient
from datetime import datetime, timedelta
import numpy as np

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="TrendScope - ÃœrÃ¼n Dedektifi", layout="wide", page_icon="ğŸ›ï¸")

# --- CSS TASARIM ---
st.markdown("""
<style>
    /* Ãœst boÅŸluk dÃ¼zeltme */
    .block-container { padding-top: 3rem !important; }
    /* Genel ayarlar */
    .stApp { background-color: #ffffff !important; color: #333 !important; }
    section[data-testid="stSidebar"] { background-color: #f8f9fa !important; }
    h1, h2, h3, p, span, div, label { color: #333 !important; }
    /* Input ve Butonlar */
    .stTextInput input, .stNumberInput input, .stSelectbox div { background-color: #fff !important; color: #333 !important; }
    .stButton>button { background-color: #007bff; color: white; border-radius: 8px; border: none; font-weight: bold; width: 100%; }
    .stButton>button:hover { background-color: #0056b3; }
</style>
""", unsafe_allow_html=True)

# --- APIFY AYARLARI ---
if "APIFY_TOKEN" in st.secrets:
    APIFY_TOKEN = st.secrets["APIFY_TOKEN"]
else:
    st.error("ğŸš¨ Hata: .streamlit/secrets.toml dosyasÄ±nda APIFY_TOKEN bulunamadÄ±.")
    st.stop()

client = ApifyClient(APIFY_TOKEN)

# --- GELÄ°ÅMÄ°Å ÃœRÃœN TESPÄ°T SÄ°STEMÄ° ---

# TÃ¼rkÃ§e karakter normalizasyonu (Ä° -> i, I -> Ä± sorunu iÃ§in)
def normalize_turkish(text):
    if not isinstance(text, str): return ""
    replacements = {
        "Ä°": "i", "I": "Ä±", "Å": "ÅŸ", "Ä": "ÄŸ", "Ãœ": "Ã¼", "Ã–": "Ã¶", "Ã‡": "Ã§"
    }
    text = text.translate(str.maketrans(replacements))
    return text.lower()

COMMERCIAL_KEYWORDS = {
    # BU KELÄ°MELERDEN 1 TANESÄ° BÄ°LE VARSA KESÄ°N ÃœRÃœNDÃœR (Puan: 5)
    "critical": [
        "sipariÅŸ", "fiyat", "tl", "â‚º", "kargo", "stok", "satÄ±n al", "kapÄ±da Ã¶deme", 
        "ÅŸeffaf kargo", "whatsapp", "dm", "iletiÅŸim", "bioda", "profildeki link", 
        "maÄŸaza", "dÃ¼kkan", "butik", "satÄ±ÅŸ", "kampanya", "indirim", "tÃ¼kenmeden", 
        "sÄ±nÄ±rlÄ± sayÄ±", "kod", "kupon", "link", "shopier", "dolap", "gardrops", 
        "trendyol", "hepsiburada", "temu", "amazon"
    ],
    # BU KELÄ°MELER DESTEKLEYÄ°CÄ°DÄ°R (Puan: 1)
    "support": [
        "Ã¼rÃ¼n", "inceleme", "Ã¶neri", "tavsiye", "denedim", "aldÄ±m", "kullandÄ±m", 
        "model", "kumaÅŸ", "beden", "renk", "kalite", "garanti", "iade", "deÄŸiÅŸim", 
        "marka", "muadil", "uygun", "performans", "detay", "kutu aÃ§Ä±lÄ±mÄ±", "paket"
    ]
}

CATEGORIES = {
    "TÃ¼mÃ¼": [],
    "ğŸ  Ev & YaÅŸam": ["mutfak gereÃ§leri", "pratik ev Ã¼rÃ¼nleri", "banyo dÃ¼zenleyici", "dekorasyon", "Ã§eyiz", "temizlik"],
    "ğŸ’„ GÃ¼zellik & BakÄ±m": ["makyaj", "cilt bakÄ±mÄ±", "kozmetik", "gÃ¼zellik", "saÃ§ bakÄ±m"],
    "ğŸ‘— Moda & Giyim": ["kombin", "moda", "tesettÃ¼r", "giyim", "elbise", "ayakkabÄ±", "Ã§anta"],
    "ğŸ’» Teknoloji & Aksesuar": ["telefon kÄ±lÄ±fÄ±", "akÄ±llÄ± saat", "teknoloji", "kulaklÄ±k", "aksesuar"],
    "ğŸ‘¶ Anne & Bebek": ["bebek Ã¼rÃ¼nleri", "oyuncak", "bebek giyim", "hamile"],
    "ğŸš— Oto & AraÃ§": ["oto aksesuar", "araba", "modifiye", "araÃ§ temizlik"]
}

# --- FONKSÄ°YONLAR ---

def score_product_intent(text):
    """
    Metni tarar ve Ã¼rÃ¼n olma ihtimalini puanlar.
    """
    if not isinstance(text, str): return 0
    text = normalize_turkish(text) # Ã–zel TÃ¼rkÃ§e Ã§evirici
    score = 0
    
    # Kritik Kelimeler (Direkt ÃœrÃ¼n)
    for word in COMMERCIAL_KEYWORDS["critical"]:
        if word in text:
            score += 5 # Bir tane bile bulsa yeterli
            
    # Destekleyici Kelimeler
    for word in COMMERCIAL_KEYWORDS["support"]:
        if word in text:
            score += 1
            
    return score

def fetch_tiktok_data(query, requested_limit):
    # KullanÄ±cÄ± 10 adet isterse biz 50 adet Ã§ekiyoruz (Buffer)
    # Ã‡Ã¼nkÃ¼ tarih filtresi ve Ã¼rÃ¼n filtresi Ã§ok veri eleyecek.
    buffer_limit = requested_limit * 5
    if buffer_limit > 300: buffer_limit = 300 
    
    try:
        run_input = {
            "searchQueries": [query],
            "resultsPerPage": buffer_limit,
            "searchRegion": "TR",
            "searchLanguage": "tr-TR",
        }
        actor_id = "clockworks/free-tiktok-scraper"
        run = client.actor(actor_id).call(run_input=run_input)
        
        if run.get("defaultDatasetId"):
            items = client.dataset(run["defaultDatasetId"]).list_items().items
            return pd.DataFrame(items)
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âš ï¸ Apify HatasÄ±: {e}")
        return pd.DataFrame()

def process_data(df, min_views, min_likes, date_limit, target_limit):
    if df.empty: return df, 0, 0
    
    # Ä°statistikler iÃ§in sayaÃ§lar
    total_fetched = len(df)
    
    # 1. BÃ¶lge Filtresi (TR)
    def get_region(meta):
        if isinstance(meta, dict): return meta.get('region', '')
        return ''

    if 'authorMeta' in df.columns:
        df['Region_Code'] = df['authorMeta'].apply(get_region)
        # Sadece kesin yabancÄ±larÄ± atÄ±yoruz, TR ve boÅŸlarÄ± tutuyoruz
        df = df[~df['Region_Code'].isin(['US', 'GB', 'DE', 'FR', 'IT', 'ES', 'BR', 'RU'])]
    
    # 2. ÃœRÃœN PUANLAMA (Kritik AdÄ±m)
    df['Product_Score'] = df['text'].apply(score_product_intent)
    
    # EÅŸik DeÄŸer: En az 1 puan. (Yani en az 1 destekleyici kelime veya 1 kritik kelime)
    # Kritik kelimeler 5 puan verdiÄŸi iÃ§in direkt geÃ§er.
    df_product = df[df['Product_Score'] >= 1].copy()
    count_after_product_filter = len(df_product) # ÃœrÃ¼n filtresinden geÃ§en sayÄ±sÄ±
    
    if df_product.empty: return pd.DataFrame(), total_fetched, 0

    # 3. SayÄ±sal DÃ¶nÃ¼ÅŸÃ¼mler
    cols = ['playCount', 'diggCount', 'shareCount', 'collectCount', 'commentCount']
    for col in cols:
        df_product[col] = pd.to_numeric(df_product.get(col, 0), errors='coerce').fillna(0)
    
    # 4. Tarih Filtresi
    if 'createTimeISO' in df_product.columns:
        df_product['createTimeISO'] = pd.to_datetime(df_product['createTimeISO'], errors='coerce', utc=True).dt.tz_localize(None)
        if date_limit:
            cutoff_date = datetime.now() - timedelta(days=date_limit)
            df_product = df_product[df_product['createTimeISO'] >= cutoff_date]
            
    # 5. Metrik Filtreleri
    df_product = df_product[df_product['playCount'] >= min_views]
    df_product = df_product[df_product['diggCount'] >= min_likes]
    
    # 6. GÃ¶rselleÅŸtirme HazÄ±rlÄ±ÄŸÄ±
    if not df_product.empty:
        # Viral Skor
        df_product['Viral_Skor'] = ((df_product['shareCount'] + df_product['collectCount']) / df_product['diggCount'].replace(0, 1)) * 100
        df_product['Viral_Skor'] = df_product['Viral_Skor'].round(1)
        
        # SÃ¼tunlar
        df_product['Resim'] = df_product['videoMeta'].apply(lambda x: x.get('coverUrl', '') if isinstance(x, dict) else '')
        df_product['Hesap'] = df_product['authorMeta'].apply(lambda x: x.get('name', '') if isinstance(x, dict) else '')
        df_product['Urun_Tahmin'] = df_product['text'].apply(lambda x: str(x)[:80] + "..." if x else "")
        
        # TÃ¼rkÃ§e Tarih
        def tr_date(d):
            if pd.isna(d): return ""
            m = {1:"Oca", 2:"Åub", 3:"Mar", 4:"Nis", 5:"May", 6:"Haz", 7:"Tem", 8:"AÄŸu", 9:"Eyl", 10:"Eki", 11:"Kas", 12:"Ara"}
            return f"{d.day} {m.get(d.month)} {d.year}"
        df_product['Tarih_Gorsel'] = df_product['createTimeISO'].apply(tr_date)
        
        # SÄ±ralama
        df_product = df_product.sort_values(by="Viral_Skor", ascending=False)
        
        return df_product.head(target_limit), total_fetched, count_after_product_filter
    
    return pd.DataFrame(), total_fetched, count_after_product_filter

# --- ARAYÃœZ ---

# SIDEBAR
with st.sidebar:
    st.header("ğŸ” GeliÅŸmiÅŸ Filtreler")
    st.markdown("---")
    
    # Tarih seÃ§eneÄŸine "TÃ¼mÃ¼" eklendi ki eski veri sorunu test edilebilsin
    date_opt = st.selectbox("ğŸ“… Tarih AralÄ±ÄŸÄ±", [7, 30, 90, 180, 365, 0], index=1, format_func=lambda x: "TÃ¼m Zamanlar" if x==0 else f"Son {x} GÃ¼n")
    
    limit_user = st.number_input("ğŸ”¢ Ä°stenen SonuÃ§ SayÄ±sÄ±", min_value=1, max_value=50, value=8, step=1)
    cat_opt = st.selectbox("ğŸ“‚ Kategori", list(CATEGORIES.keys()))
    
    st.markdown("### Limitler")
    min_view_inp = st.number_input("ğŸ‘ï¸ Min. Ä°zlenme", value=0, step=500)
    min_like_inp = st.number_input("â¤ï¸ Min. BeÄŸeni", value=0, step=10)
    
    hashtag_filter = st.text_input("Hashtag (#)", placeholder="Ã¶rn: indirim")

# ANA EKRAN
st.title("TrendScope TR - AkÄ±llÄ± ÃœrÃ¼n Analizi")
st.write("TikTok verilerini tarar, 'ÃœrÃ¼n' ve 'SatÄ±ÅŸ' odaklÄ± olmayanlarÄ± yapay zeka mantÄ±ÄŸÄ±yla eler.")

search_query = st.text_input("", placeholder="ÃœrÃ¼n adÄ±, marka veya anahtar kelime...", label_visibility="collapsed")

if st.button("ğŸš€ ÃœRÃœNLERÄ° BUL", use_container_width=True):
    
    # Sorgu
    final_query = ""
    if cat_opt != "TÃ¼mÃ¼":
        import random
        base_keyword = random.choice(CATEGORIES[cat_opt])
        final_query = f"{base_keyword}"
    
    if search_query:
        final_query = f"{search_query} {final_query}"
        
    if hashtag_filter:
        clean_tag = hashtag_filter.replace('#','')
        final_query = f"{final_query} #{clean_tag}"
        
    if not final_query.strip():
        final_query = "inceleme fiyat sipariÅŸ"

    with st.spinner(f"ğŸ“¡ Veriler Ã§ekiliyor ve analiz ediliyor (Hedef: {limit_user} adet)..."):
        
        # 1. Apify'dan Veri Ã‡ek
        raw_df = fetch_tiktok_data(final_query, limit_user)
        
        # 2. Ä°ÅŸle ve Filtrele
        clean_df, total_scraped, total_products = process_data(raw_df, min_view_inp, min_like_inp, date_opt, limit_user)
        
        if not clean_df.empty:
            st.session_state.results = clean_df
            st.success(f"âœ… BaÅŸarÄ±lÄ±! {len(clean_df)} adet nitelikli Ã¼rÃ¼n videosu bulundu.")
            
            # Bilgilendirme Metni
            st.caption(f"ğŸ” Analiz DetayÄ±: Toplam {total_scraped} video tarandÄ±. Bunlardan {total_products} tanesi 'ÃœrÃ¼n' olarak tespit edildi. Tarih ve limit filtrelerinden sonra {len(clean_df)} adet gÃ¶steriliyor.")
        
        else:
            st.warning("âš ï¸ SonuÃ§ bulunamadÄ±.")
            if total_scraped > 0:
                st.error(f"""
                **Analiz Raporu:**
                - Apify'dan **{total_scraped}** adet video Ã§ekildi.
                - Bu videolardan **{total_products}** tanesi 'ÃœrÃ¼n' kriterine uydu.
                - Ancak **Tarih Filtresi ({date_opt if date_opt else 'TÃ¼mÃ¼'})** veya Ä°zlenme Limiti sebebiyle hepsi elendi.
                
                **Ã–neri:** Sol taraftan 'Tarih AralÄ±ÄŸÄ±'nÄ± artÄ±rÄ±n (Ã¶rn: Son 180 GÃ¼n veya 365 GÃ¼n) Ã§Ã¼nkÃ¼ Apify eski popÃ¼ler videolarÄ± getiriyor olabilir.
                """)
            else:
                st.error("Apify kaynaklÄ± veri gelmedi veya baÄŸlantÄ± sorunu var.")
            st.session_state.results = None

# TABLO
if 'results' in st.session_state and st.session_state.results is not None:
    df = st.session_state.results
    
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Listelenen", len(df))
    m2.metric("Ort. Ä°zlenme", f"{int(df['playCount'].mean()):,}")
    m3.metric("Ort. Viral Skor", f"{df['Viral_Skor'].mean():.1f}")
    m4.metric("En YÃ¼ksek BeÄŸeni", f"{int(df['diggCount'].max()):,}")
    
    st.markdown("---")
    
    st.data_editor(
        df[[
            "Resim", 
            "Urun_Tahmin", 
            "Hesap", 
            "Viral_Skor", 
            "playCount", 
            "diggCount", 
            "shareCount", 
            "webVideoUrl",
            "Tarih_Gorsel"
        ]],
        column_config={
            "Resim": st.column_config.ImageColumn("Video", width="small"),
            "Urun_Tahmin": st.column_config.TextColumn("ÃœrÃ¼n / Ä°Ã§erik", width="medium"),
            "Hesap": st.column_config.TextColumn("SatÄ±cÄ±", width="small"),
            "Viral_Skor": st.column_config.ProgressColumn("Viral PuanÄ±", format="%.1f", min_value=0, max_value=100),
            "playCount": st.column_config.NumberColumn("Ä°zlenme"),
            "diggCount": st.column_config.NumberColumn("BeÄŸeni"),
            "shareCount": st.column_config.NumberColumn("PaylaÅŸÄ±m"),
            "webVideoUrl": st.column_config.LinkColumn("Link", display_text="Ä°zle â–¶ï¸"),
            "Tarih_Gorsel": st.column_config.TextColumn("YayÄ±n Tarihi")
        },
        use_container_width=True,
        hide_index=True,
        height=800
    )
else:
    st.markdown("""
    <div style='text-align: center; color: grey; padding: 50px;'>
        <h3>HenÃ¼z Analiz YapÄ±lmadÄ±</h3>
        <p>Sol taraftan bir kategori seÃ§in veya spesifik bir Ã¼rÃ¼n adÄ± yazÄ±n.</p>
    </div>
    """, unsafe_allow_html=True)